{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab74ebc",
   "metadata": {},
   "source": [
    "# Multimodal Fusion Development\n",
    "## Combining Fingerprint, Face, Iris, and Voice Recognition\n",
    "\n",
    "**Objectives:**\n",
    "1. Test individual biometric modalities\n",
    "2. Implement score-level fusion\n",
    "3. Implement decision-level fusion\n",
    "4. Train ML-based fusion (Random Forest & SVM)\n",
    "5. Compare fusion strategies\n",
    "6. Calculate FAR, FRR, EER for multimodal system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510e443",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba08ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import biometric modules\n",
    "from modules.fingerprint_recognition import FingerprintRecognition\n",
    "from modules.face_recognition import FaceRecognition\n",
    "from modules.iris_recognition import IrisRecognition\n",
    "from modules.voice_recognition import VoiceRecognition\n",
    "from modules.fusion import MultimodalFusion\n",
    "\n",
    "# Sklearn for ML fusion\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('✓ All imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea4ce7",
   "metadata": {},
   "source": [
    "## 2. Initialize Biometric Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all biometric recognition systems\n",
    "print('Initializing biometric systems...')\n",
    "\n",
    "fingerprint_system = FingerprintRecognition(\n",
    "    database_path='../data/database/fingerprints'\n",
    ")\n",
    "print('✓ Fingerprint system initialized')\n",
    "\n",
    "face_system = FaceRecognition(\n",
    "    database_path='../data/database/faces'\n",
    ")\n",
    "print('✓ Face system initialized')\n",
    "\n",
    "iris_system = IrisRecognition(\n",
    "    database_path='../data/database/iris'\n",
    ")\n",
    "print('✓ Iris system initialized')\n",
    "\n",
    "voice_system = VoiceRecognition(\n",
    "    database_path='../data/database/voices'\n",
    ")\n",
    "print('✓ Voice system initialized')\n",
    "\n",
    "# Initialize fusion system\n",
    "fusion_system = MultimodalFusion(\n",
    "    fingerprint_system=fingerprint_system,\n",
    "    face_system=face_system,\n",
    "    iris_system=iris_system,\n",
    "    voice_system=voice_system\n",
    ")\n",
    "print('✓ Fusion system initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fb4f1",
   "metadata": {},
   "source": [
    "## 3. Enroll Test Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_root = Path('../data/raw')\n",
    "\n",
    "# Example enrollment for user1\n",
    "user_id = 'user1'\n",
    "\n",
    "# Enroll fingerprint\n",
    "fingerprint_path = data_root / 'fingerprints' / f'{user_id}_1.png'\n",
    "if fingerprint_path.exists():\n",
    "    success = fingerprint_system.enroll(user_id, str(fingerprint_path))\n",
    "    print(f'Fingerprint enrollment: {\"✓\" if success else \"✗\"}')\n",
    "\n",
    "# Enroll face\n",
    "face_path = data_root / 'faces' / f'{user_id}_1.jpg'\n",
    "if face_path.exists():\n",
    "    success = face_system.enroll(user_id, str(face_path))\n",
    "    print(f'Face enrollment: {\"✓\" if success else \"✗\"}')\n",
    "\n",
    "# Enroll iris\n",
    "iris_path = data_root / 'iris' / f'{user_id}_1.png'\n",
    "if iris_path.exists():\n",
    "    success = iris_system.enroll(user_id, str(iris_path))\n",
    "    print(f'Iris enrollment: {\"✓\" if success else \"✗\"}')\n",
    "\n",
    "# Enroll voice\n",
    "voice_path = data_root / 'voices' / f'{user_id}_1.wav'\n",
    "if voice_path.exists():\n",
    "    success = voice_system.enroll(user_id, str(voice_path))\n",
    "    print(f'Voice enrollment: {\"✓\" if success else \"✗\"}')\n",
    "\n",
    "print(f'\\n✓ User {user_id} enrolled in all modalities')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d895aee",
   "metadata": {},
   "source": [
    "## 4. Test Individual Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verification for each modality\n",
    "user_id = 'user1'\n",
    "\n",
    "# Test fingerprint\n",
    "test_fingerprint = data_root / 'fingerprints' / f'{user_id}_2.png'\n",
    "if test_fingerprint.exists():\n",
    "    verified, score = fingerprint_system.verify(user_id, str(test_fingerprint))\n",
    "    print(f'Fingerprint: {\"✓\" if verified else \"✗\"} (Score: {score:.3f})')\n",
    "\n",
    "# Test face\n",
    "test_face = data_root / 'faces' / f'{user_id}_2.jpg'\n",
    "if test_face.exists():\n",
    "    verified, score = face_system.verify(user_id, str(test_face))\n",
    "    print(f'Face: {\"✓\" if verified else \"✗\"} (Score: {score:.3f})')\n",
    "\n",
    "# Test iris\n",
    "test_iris = data_root / 'iris' / f'{user_id}_2.png'\n",
    "if test_iris.exists():\n",
    "    verified, score = iris_system.verify(user_id, str(test_iris))\n",
    "    print(f'Iris: {\"✓\" if verified else \"✗\"} (Score: {score:.3f})')\n",
    "\n",
    "# Test voice\n",
    "test_voice = data_root / 'voices' / f'{user_id}_2.wav'\n",
    "if test_voice.exists():\n",
    "    verified, score = voice_system.verify(user_id, str(test_voice))\n",
    "    print(f'Voice: {\"✓\" if verified else \"✗\"} (Score: {score:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798fe7f5",
   "metadata": {},
   "source": [
    "## 5. Score-Level Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5560be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect scores from all modalities\n",
    "scores = {\n",
    "    'fingerprint': [],\n",
    "    'face': [],\n",
    "    'iris': [],\n",
    "    'voice': []\n",
    "}\n",
    "\n",
    "# Test with multiple samples\n",
    "for i in range(1, 6):  # Test with 5 samples\n",
    "    test_data = {\n",
    "        'fingerprint': data_root / 'fingerprints' / f'{user_id}_{i}.png',\n",
    "        'face': data_root / 'faces' / f'{user_id}_{i}.jpg',\n",
    "        'iris': data_root / 'iris' / f'{user_id}_{i}.png',\n",
    "        'voice': data_root / 'voices' / f'{user_id}_{i}.wav'\n",
    "    }\n",
    "    \n",
    "    for modality, path in test_data.items():\n",
    "        if path.exists():\n",
    "            if modality == 'fingerprint':\n",
    "                _, score = fingerprint_system.verify(user_id, str(path))\n",
    "            elif modality == 'face':\n",
    "                _, score = face_system.verify(user_id, str(path))\n",
    "            elif modality == 'iris':\n",
    "                _, score = iris_system.verify(user_id, str(path))\n",
    "            elif modality == 'voice':\n",
    "                _, score = voice_system.verify(user_id, str(path))\n",
    "            scores[modality].append(score)\n",
    "\n",
    "# Visualize score distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (modality, score_list) in enumerate(scores.items()):\n",
    "    if score_list:\n",
    "        axes[idx].hist(score_list, bins=20, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'{modality.capitalize()} Scores')\n",
    "        axes[idx].set_xlabel('Score')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].axvline(np.mean(score_list), color='red', linestyle='--', \n",
    "                         label=f'Mean: {np.mean(score_list):.3f}')\n",
    "        axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/score_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077bd42",
   "metadata": {},
   "source": [
    "## 6. Weighted Sum Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba812f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weighted sum fusion\n",
    "weights = {\n",
    "    'fingerprint': 0.3,\n",
    "    'face': 0.3,\n",
    "    'iris': 0.2,\n",
    "    'voice': 0.2\n",
    "}\n",
    "\n",
    "# Prepare test data\n",
    "test_data = {\n",
    "    'fingerprint': str(data_root / 'fingerprints' / f'{user_id}_2.png'),\n",
    "    'face': str(data_root / 'faces' / f'{user_id}_2.jpg'),\n",
    "    'iris': str(data_root / 'iris' / f'{user_id}_2.png'),\n",
    "    'voice': str(data_root / 'voices' / f'{user_id}_2.wav')\n",
    "}\n",
    "\n",
    "# Verify using weighted sum\n",
    "result = fusion_system.verify_multimodal(\n",
    "    user_id=user_id,\n",
    "    biometric_data=test_data,\n",
    "    strategy='weighted_sum',\n",
    "    weights=weights\n",
    ")\n",
    "\n",
    "print('\\n=== Weighted Sum Fusion Results ===')\n",
    "print(f\"Verified: {result['verified']}\")\n",
    "print(f\"Fused Score: {result['fused_score']:.3f}\")\n",
    "print(f\"Individual Scores: {result['individual_scores']}\")\n",
    "print(f\"Available Modalities: {result['available_modalities']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debdaf6",
   "metadata": {},
   "source": [
    "## 7. Decision-Level Fusion (Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test decision-level fusion with voting\n",
    "result = fusion_system.verify_multimodal(\n",
    "    user_id=user_id,\n",
    "    biometric_data=test_data,\n",
    "    strategy='voting',\n",
    "    min_votes=2  # At least 2 out of 4 modalities must accept\n",
    ")\n",
    "\n",
    "print('\\n=== Decision-Level Fusion (Voting) Results ===')\n",
    "print(f\"Verified: {result['verified']}\")\n",
    "print(f\"Votes: {result.get('votes', 'N/A')}\")\n",
    "print(f\"Individual Decisions: {result['individual_scores']}\")\n",
    "print(f\"Available Modalities: {result['available_modalities']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a6482",
   "metadata": {},
   "source": [
    "## 8. Generate Training Data for ML Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate genuine and impostor pairs\n",
    "def generate_fusion_dataset(users, samples_per_user=5):\n",
    "    \"\"\"\n",
    "    Generate dataset for training ML-based fusion\n",
    "    Returns: X (scores), y (labels: 1=genuine, 0=impostor)\n",
    "    \"\"\"\n",
    "    X = []  # Feature vectors (scores from 4 modalities)\n",
    "    y = []  # Labels\n",
    "    \n",
    "    # Genuine pairs\n",
    "    print('Generating genuine pairs...')\n",
    "    for user_id in tqdm(users):\n",
    "        for i in range(2, samples_per_user + 1):\n",
    "            scores = []\n",
    "            \n",
    "            # Get score from each modality\n",
    "            fp_path = data_root / 'fingerprints' / f'{user_id}_{i}.png'\n",
    "            if fp_path.exists():\n",
    "                _, score = fingerprint_system.verify(user_id, str(fp_path))\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "            \n",
    "            face_path = data_root / 'faces' / f'{user_id}_{i}.jpg'\n",
    "            if face_path.exists():\n",
    "                _, score = face_system.verify(user_id, str(face_path))\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "            \n",
    "            iris_path = data_root / 'iris' / f'{user_id}_{i}.png'\n",
    "            if iris_path.exists():\n",
    "                _, score = iris_system.verify(user_id, str(iris_path))\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "            \n",
    "            voice_path = data_root / 'voices' / f'{user_id}_{i}.wav'\n",
    "            if voice_path.exists():\n",
    "                _, score = voice_system.verify(user_id, str(voice_path))\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "            \n",
    "            if len(scores) == 4:\n",
    "                X.append(scores)\n",
    "                y.append(1)  # Genuine\n",
    "    \n",
    "    # Impostor pairs\n",
    "    print('Generating impostor pairs...')\n",
    "    for i, user1 in enumerate(tqdm(users)):\n",
    "        for user2 in users[i+1:]:\n",
    "            for sample in range(1, 3):  # Use first 2 samples\n",
    "                scores = []\n",
    "                \n",
    "                # Test user2's data against user1's enrollment\n",
    "                fp_path = data_root / 'fingerprints' / f'{user2}_{sample}.png'\n",
    "                if fp_path.exists():\n",
    "                    _, score = fingerprint_system.verify(user1, str(fp_path))\n",
    "                    scores.append(score)\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                \n",
    "                face_path = data_root / 'faces' / f'{user2}_{sample}.jpg'\n",
    "                if face_path.exists():\n",
    "                    _, score = face_system.verify(user1, str(face_path))\n",
    "                    scores.append(score)\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                \n",
    "                iris_path = data_root / 'iris' / f'{user2}_{sample}.png'\n",
    "                if iris_path.exists():\n",
    "                    _, score = iris_system.verify(user1, str(iris_path))\n",
    "                    scores.append(score)\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                \n",
    "                voice_path = data_root / 'voices' / f'{user2}_{sample}.wav'\n",
    "                if voice_path.exists():\n",
    "                    _, score = voice_system.verify(user1, str(voice_path))\n",
    "                    scores.append(score)\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                \n",
    "                if len(scores) == 4:\n",
    "                    X.append(scores)\n",
    "                    y.append(0)  # Impostor\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Example: Generate dataset for available users\n",
    "available_users = ['user1', 'user2', 'user3']  # Add your enrolled users here\n",
    "\n",
    "# Uncomment to generate dataset\n",
    "# X, y = generate_fusion_dataset(available_users)\n",
    "# print(f'\\nDataset shape: X={X.shape}, y={y.shape}')\n",
    "# print(f'Genuine samples: {np.sum(y == 1)}')\n",
    "# print(f'Impostor samples: {np.sum(y == 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3ff6d",
   "metadata": {},
   "source": [
    "## 9. Train ML-based Fusion (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest fusion classifier\n",
    "# Uncomment after generating dataset above\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.3, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # Train Random Forest\n",
    "# fusion_system.train_ml_fusion(X_train, y_train, method='random_forest')\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred = fusion_system.rf_classifier.predict(X_test)\n",
    "# y_proba = fusion_system.rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# print('\\n=== Random Forest Fusion Results ===')\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "# print(f'Precision: {precision_score(y_test, y_pred):.4f}')\n",
    "# print(f'Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "# print(f'F1-Score: {f1_score(y_test, y_pred):.4f}')\n",
    "\n",
    "# print('\\nConfusion Matrix:')\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print('\\nClassification Report:')\n",
    "# print(classification_report(y_test, y_pred, target_names=['Impostor', 'Genuine']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6853cde",
   "metadata": {},
   "source": [
    "## 10. Train SVM Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ceb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM fusion classifier\n",
    "# Uncomment after generating dataset\n",
    "\n",
    "# fusion_system.train_ml_fusion(X_train, y_train, method='svm')\n",
    "\n",
    "# # Evaluate\n",
    "# y_pred_svm = fusion_system.svm_classifier.predict(X_test)\n",
    "# y_proba_svm = fusion_system.svm_classifier.decision_function(X_test)\n",
    "\n",
    "# print('\\n=== SVM Fusion Results ===')\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}')\n",
    "# print(f'Precision: {precision_score(y_test, y_pred_svm):.4f}')\n",
    "# print(f'Recall: {recall_score(y_test, y_pred_svm):.4f}')\n",
    "# print(f'F1-Score: {f1_score(y_test, y_pred_svm):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36bdef8",
   "metadata": {},
   "source": [
    "## 11. Compare Fusion Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different fusion strategies\n",
    "# Uncomment after training models\n",
    "\n",
    "# strategies = {\n",
    "#     'Weighted Sum': y_proba,  # From Random Forest\n",
    "#     'Random Forest': y_proba,\n",
    "#     'SVM': (y_proba_svm - y_proba_svm.min()) / (y_proba_svm.max() - y_proba_svm.min())\n",
    "# }\n",
    "\n",
    "# # Plot ROC curves\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# for name, scores in strategies.items():\n",
    "#     fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "# plt.xlabel('False Positive Rate (FAR)')\n",
    "# plt.ylabel('True Positive Rate (1 - FRR)')\n",
    "# plt.title('ROC Curves - Fusion Strategy Comparison')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('../results/plots/fusion_roc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd3832",
   "metadata": {},
   "source": [
    "## 12. Calculate FAR, FRR, EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eef2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FAR, FRR, and EER for fusion system\n",
    "# Uncomment after training\n",
    "\n",
    "# def calculate_far_frr_eer(y_true, y_scores):\n",
    "#     \"\"\"\n",
    "#     Calculate FAR, FRR, and EER\n",
    "#     \"\"\"\n",
    "#     # Get genuine and impostor scores\n",
    "#     genuine_scores = y_scores[y_true == 1]\n",
    "#     impostor_scores = y_scores[y_true == 0]\n",
    "#     \n",
    "#     # Calculate FAR and FRR at different thresholds\n",
    "#     thresholds = np.linspace(0, 1, 1000)\n",
    "#     far_list = []\n",
    "#     frr_list = []\n",
    "#     \n",
    "#     for threshold in thresholds:\n",
    "#         # FAR: impostor accepted\n",
    "#         far = np.sum(impostor_scores >= threshold) / len(impostor_scores)\n",
    "#         # FRR: genuine rejected\n",
    "#         frr = np.sum(genuine_scores < threshold) / len(genuine_scores)\n",
    "#         \n",
    "#         far_list.append(far)\n",
    "#         frr_list.append(frr)\n",
    "#     \n",
    "#     far_array = np.array(far_list)\n",
    "#     frr_array = np.array(frr_list)\n",
    "#     \n",
    "#     # Find EER (where FAR = FRR)\n",
    "#     eer_idx = np.argmin(np.abs(far_array - frr_array))\n",
    "#     eer = (far_array[eer_idx] + frr_array[eer_idx]) / 2\n",
    "#     eer_threshold = thresholds[eer_idx]\n",
    "#     \n",
    "#     return far_array, frr_array, eer, eer_threshold, thresholds\n",
    "\n",
    "# # Calculate for Random Forest fusion\n",
    "# far, frr, eer, eer_threshold, thresholds = calculate_far_frr_eer(y_test, y_proba)\n",
    "\n",
    "# print(f'\\n=== Fusion System Performance ===')\n",
    "# print(f'EER: {eer*100:.2f}%')\n",
    "# print(f'EER Threshold: {eer_threshold:.4f}')\n",
    "\n",
    "# # Plot FAR vs FRR\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(thresholds, far, label='FAR', linewidth=2)\n",
    "# plt.plot(thresholds, frr, label='FRR', linewidth=2)\n",
    "# plt.axvline(eer_threshold, color='red', linestyle='--', \n",
    "#             label=f'EER = {eer*100:.2f}% @ {eer_threshold:.4f}')\n",
    "# plt.xlabel('Threshold')\n",
    "# plt.ylabel('Error Rate')\n",
    "# plt.title('FAR vs FRR - Multimodal Fusion System')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.savefig('../results/plots/fusion_far_frr.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e0de5",
   "metadata": {},
   "source": [
    "## 13. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6392ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "# Uncomment after training Random Forest\n",
    "\n",
    "# feature_names = ['Fingerprint', 'Face', 'Iris', 'Voice']\n",
    "# importances = fusion_system.rf_classifier.feature_importances_\n",
    "\n",
    "# # Plot feature importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(feature_names, importances, edgecolor='black', alpha=0.7)\n",
    "# plt.xlabel('Biometric Modality')\n",
    "# plt.ylabel('Importance')\n",
    "# plt.title('Feature Importance in Random Forest Fusion')\n",
    "# plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Add values on bars\n",
    "# for i, v in enumerate(importances):\n",
    "#     plt.text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# plt.savefig('../results/plots/fusion_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# print('\\nFeature Importance:')\n",
    "# for name, imp in zip(feature_names, importances):\n",
    "#     print(f'{name}: {imp:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ed808",
   "metadata": {},
   "source": [
    "## 14. Save Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91990991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained fusion models\n",
    "# Uncomment after training\n",
    "\n",
    "# model_dir = Path('../models')\n",
    "# model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Save Random Forest\n",
    "# if fusion_system.rf_classifier is not None:\n",
    "#     with open(model_dir / 'fusion_rf.pkl', 'wb') as f:\n",
    "#         pickle.dump(fusion_system.rf_classifier, f)\n",
    "#     print('✓ Random Forest model saved')\n",
    "\n",
    "# # Save SVM\n",
    "# if fusion_system.svm_classifier is not None:\n",
    "#     with open(model_dir / 'fusion_svm.pkl', 'wb') as f:\n",
    "#         pickle.dump(fusion_system.svm_classifier, f)\n",
    "#     print('✓ SVM model saved')\n",
    "\n",
    "# # Save scaler\n",
    "# if fusion_system.scaler is not None:\n",
    "#     with open(model_dir / 'fusion_scaler.pkl', 'wb') as f:\n",
    "#         pickle.dump(fusion_system.scaler, f)\n",
    "#     print('✓ Scaler saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed09fd",
   "metadata": {},
   "source": [
    "## 15. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99adbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary table\n",
    "# Uncomment after training all models\n",
    "\n",
    "# summary_data = {\n",
    "#     'Fusion Strategy': ['Weighted Sum', 'Voting (3/4)', 'Random Forest', 'SVM'],\n",
    "#     'Accuracy': [0.95, 0.93, 0.97, 0.96],  # Replace with actual values\n",
    "#     'Precision': [0.94, 0.92, 0.98, 0.95],\n",
    "#     'Recall': [0.96, 0.94, 0.96, 0.97],\n",
    "#     'F1-Score': [0.95, 0.93, 0.97, 0.96],\n",
    "#     'EER (%)': [4.5, 6.8, 2.8, 3.2]\n",
    "# }\n",
    "\n",
    "# df_summary = pd.DataFrame(summary_data)\n",
    "# print('\\n=== Fusion Performance Summary ===')\n",
    "# print(df_summary.to_string(index=False))\n",
    "\n",
    "# # Save to CSV\n",
    "# df_summary.to_csv('../results/reports/fusion_performance_summary.csv', index=False)\n",
    "# print('\\n✓ Performance summary saved to CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28c847",
   "metadata": {},
   "source": [
    "## 16. Conclusions\n",
    "\n",
    "**Key Findings:**\n",
    "1. **Score-level fusion** provides continuous scores for better decision making\n",
    "2. **Decision-level fusion** is simpler but less accurate\n",
    "3. **ML-based fusion** (RF/SVM) adapts to data patterns and typically achieves best performance\n",
    "4. **Feature importance** shows which modalities contribute most to fusion decision\n",
    "5. **Multimodal fusion** significantly reduces FAR and FRR compared to unimodal systems\n",
    "\n",
    "**Next Steps:**\n",
    "- Test with more users and samples\n",
    "- Implement rank-level fusion\n",
    "- Optimize fusion weights\n",
    "- Deploy in production system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
