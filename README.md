# ğŸ” Multimodal Biometric Authentication System

A comprehensive biometric authentication system implementing **4 biometric modalities**: Fingerprint, Iris, Face, and Voice recognition with a modern web interface.

![alt text](image.png)

---

## ğŸ“‹ Table of Contents
- [Features](#-features)
- [System Architecture](#-system-architecture)
- [Technologies Used](#-technologies-used)
- [Installation](#-installation)
- [Usage](#-usage)
- [Biometric Modalities](#-biometric-modalities)
- [Project Structure](#-project-structure)
- [Performance](#-performance)
- [Security](#-security)
- [Screenshots](#-screenshots)
- [Contributing](#-contributing)
- [License](#-license)

---

## âœ¨ Features

### Core Functionalities
- **4 Biometric Modalities**: Fingerprint, Iris, Face, and Voice
- **3 Operating Modes**:
  - ğŸ“ **Enrollment**: Register new users with biometric data
  - ğŸ” **Verification (1:1)**: Verify claimed identity
  - ğŸ” **Identification (1:N)**: Identify unknown person from database
- **Database Management**: Add, view, delete users per modality
- **Web Interface**: Modern Streamlit-based UI with real-time processing

### Advanced Features
- Multi-eye support for iris (Left/Right separation)
- Eye side auto-detection with validation
- Webcam capture for face enrollment/verification
- Live audio recording for voice authentication
- Quality assessment for iris images
- Configurable thresholds and algorithm parameters
- Visualization of similarity scores

---

## ğŸ—ï¸ System Architecture

The system follows a **modular, layered architecture** designed for scalability and maintainability:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESENTATION LAYER (Streamlit)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Dashboardâ”‚ Enrollment â”‚ Verification â”‚ Identification â”‚ Settings â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BUSINESS LOGIC LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              Recognition Module Interface                    â”‚     â”‚
â”‚  â”‚  â€¢ enroll(user_id, sample) â†’ bool                            â”‚     â”‚
â”‚  â”‚  â€¢ verify(user_id, sample, threshold) â†’ (bool, similarity)   â”‚     â”‚
â”‚  â”‚  â€¢ identify(sample, threshold) â†’ List[(user_id, score)]      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚Fingerprint â”‚    Iris     â”‚    Face    â”‚    Voice     â”‚             â”‚
â”‚  â”‚Recognition â”‚ Recognition â”‚Recognition â”‚ Recognition  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚              â”‚              â”‚
           â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ALGORITHM PROCESSING LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   SIFT   â”‚  â”‚ Daugman's â”‚  â”‚ VGG-Face â”‚  â”‚ ECAPA-TDNN  â”‚           â”‚
â”‚  â”‚  + FLANN â”‚  â”‚ Algorithm â”‚  â”‚  (Deep   â”‚  â”‚  (Speaker   â”‚           â”‚
â”‚  â”‚ Matching â”‚  â”‚  + Gabor  â”‚  â”‚  Face)   â”‚  â”‚  Embedding) â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                       â”‚
â”‚  Image Processing      Audio Processing      Deep Learning            â”‚
â”‚  â€¢ OpenCV             â€¢ librosa              â€¢ TensorFlow/Keras       â”‚
â”‚  â€¢ NumPy              â€¢ soundfile            â€¢ PyTorch                â”‚
â”‚  â€¢ scikit-image       â€¢ VAD                  â€¢ DeepFace/SpeechBrain   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA PERSISTENCE LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚              Template Database (Pickle Format)              â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚      â”‚
â”‚  â”‚  â”‚Fingerprints â”‚   Iris   â”‚   Faces   â”‚   Voices    â”‚       â”‚      â”‚
â”‚  â”‚  â”‚   (SIFT     â”‚ (Binary  â”‚ (4096-D   â”‚  (192-D     â”‚       â”‚      â”‚
â”‚  â”‚  â”‚  features)  â”‚  codes)  â”‚ vectors)  â”‚ embeddings) â”‚       â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                       â”‚
â”‚  File System: data/database/{fingerprints|iris|faces|voices}/         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Highlights

#### 1. **Presentation Layer**
- **Technology**: Streamlit web framework
- **Components**: 5 main pages (Dashboard, Enrollment, Verification, Identification, Settings)
- **Features**: Interactive UI, real-time feedback, webcam/microphone integration
- **File**: `app.py` (1935 lines)

#### 2. **Business Logic Layer**
- **Design Pattern**: Uniform interface across all modalities
- **Core Operations**: 
  - `enroll()`: Register biometric template
  - `verify()`: 1:1 matching against claimed identity
  - `identify()`: 1:N search across database
- **Modules**: 4 independent recognition modules
- **Location**: `modules/` directory

#### 3. **Algorithm Processing Layer**
- **Fingerprint**: SIFT keypoint extraction + FLANN matcher
- **Iris**: Hough Transform segmentation + Gabor wavelets + Hamming distance
- **Face**: RetinaFace detection + VGG-Face embedding + Cosine similarity
- **Voice**: VAD preprocessing + ECAPA-TDNN embedding + Cosine similarity

#### 4. **Data Persistence Layer**
- **Storage**: Pickle-based serialization (not production-ready, use database in real deployment)
- **Templates**: Privacy-preserving representations (features, not raw biometrics)
- **Organization**: Separate folders per modality

### Data Flow Example (Verification)

```
User uploads fingerprint image
        â”‚
        â–¼
[Streamlit UI] receives image file
        â”‚
        â–¼
[FingerprintRecognition.verify()] called
        â”‚
        â”œâ”€â†’ Preprocess: CLAHE + Gaussian blur
        â”‚
        â”œâ”€â†’ Extract: SIFT features from query image
        â”‚
        â”œâ”€â†’ Load: Enrolled template from database
        â”‚
        â”œâ”€â†’ Match: FLANN-based KNN matching
        â”‚
        â”œâ”€â†’ Filter: Lowe's ratio test (0.75)
        â”‚
        â””â”€â†’ Decide: >= threshold â†’ VERIFIED
        â”‚
        â–¼
[Streamlit UI] displays result with similarity score
```

---

## ğŸ› ï¸ Technologies Used

### Computer Vision
- **OpenCV**: Image processing, SIFT feature extraction, Hough Transform
- **NumPy**: Numerical operations, array processing
- **scikit-image**: Image enhancement

### Deep Learning
- **TensorFlow/Keras**: Backend for DeepFace
- **PyTorch**: Backend for SpeechBrain
- **DeepFace**: Face recognition with VGG-Face model
- **SpeechBrain**: ECAPA-TDNN for speaker recognition

### Audio Processing
- **librosa**: Audio feature extraction, VAD
- **soundfile**: Audio I/O operations

### Web Framework
- **Streamlit**: Interactive web interface
- **Plotly**: Interactive visualizations
- **Pandas**: Data manipulation and display

### Algorithms Implemented
1. **Fingerprint**: SIFT (Scale-Invariant Feature Transform) + FLANN matching
2. **Iris**: Daugman's Rubber Sheet Model + Gabor wavelets
3. **Face**: VGG-Face (DeepFace) + RetinaFace detector
4. **Voice**: ECAPA-TDNN speaker embeddings + Cosine similarity

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.12
- pip (Python package manager)
- Webcam (optional, for face capture)
- Microphone (optional, for voice recording)

### Step 1: Clone Repository
```bash
git clone https://github.com/lewisMVP/multimodal-biometric-authentication.git
cd multimodal-biometric-authentication
```

### Step 2: Create Virtual Environment (Recommended)
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

**Note**: Installation may take 5-10 minutes due to TensorFlow and PyTorch.

### Step 4: Run Application
```bash
streamlit run app.py
```

The application will open in your default browser at `http://localhost:8501`

---

## ğŸš€ Usage

### 1. Enrollment
1. Navigate to **Enrollment** page
2. Enter **User ID**
3. Select **Biometric Modality** (Fingerprint/Iris/Face/Voice)
4. Upload sample or use live capture
5. For Iris: Select eye side (Left/Right)
6. Click **Enroll** button

### 2. Verification (1:1)
1. Navigate to **Verification** page
2. Enter **User ID** to verify
3. Select **Biometric Modality**
4. Upload/capture biometric sample
5. Click **Verify** button
6. View result: âœ… VERIFIED or âŒ REJECTED

### 3. Identification (1:N)
1. Navigate to **Identification** page
2. Select **Biometric Modality**
3. Upload/capture biometric sample
4. Click **Identify** button
5. View ranked results with similarity scores

### 4. Database Management
1. Navigate to **Settings** page
2. Scroll to **Database Management**
3. Select modality to manage
4. View enrolled users
5. Delete individual users or clear entire database

---

## ğŸ”¬ Biometric Modalities

### ğŸ‘† Fingerprint Recognition

**Algorithm**: SIFT (Scale-Invariant Feature Transform)

**Pipeline**:
1. Preprocessing: CLAHE + Gaussian Blur
2. Feature Extraction: 500 SIFT keypoints
3. Matching: FLANN-based KNN with Lowe's ratio test (0.75)

**Advantages**:
- Scale and rotation invariant
- Robust to noise
- High accuracy (10-15% better than ORB)

---

### ğŸ‘ï¸ Iris Recognition

**Algorithm**: Daugman's Rubber Sheet Model

**Pipeline**:
1. Segmentation: Hough Circle Transform (iris + pupil)
2. Normalization: Polar transformation (64Ã—512)
3. Feature Extraction: Gabor wavelets (4 orientations, median threshold)
4. Matching: Hamming Distance with rotation handling

**Special Features**:
- Multi-eye support (Left/Right separation)
- Eye side auto-detection
- Quality assessment (sharpness, contrast, illumination, occlusion)
- Threshold: 0.65 similarity (0.35 Hamming distance)

**Advantages**:
- Highly distinctive (low FAR)
- Stable over lifetime
- Difficult to forge

---

### ğŸ˜Š Face Recognition

**Algorithm**: VGG-Face (DeepFace framework)

**Pipeline**:
1. Detection: RetinaFace detector
2. Alignment: Facial landmarks
3. Embedding: VGG-Face CNN (4096-D vector)
4. Matching: Cosine similarity

**Features**:
- Upload image or webcam capture
- Real-time detection preview
- Multi-image storage per user

**Advantages**:
- Non-intrusive
- Fast detection
- High accuracy with deep learning

---

### ğŸ¤ Voice Recognition

**Algorithm**: ECAPA-TDNN (Emphasized Channel Attention, Propagation and Aggregation in TDNN)

**Pipeline**:
1. Audio Processing: 16kHz resampling, VAD
2. Normalization: Peak normalization to 95%
3. Embedding: ECAPA-TDNN (192-D vector)
4. Matching: Cosine similarity

**Features**:
- Upload audio file or live recording
- Quality validation (duration, energy, RMS)
- Threshold: 0.50 (optimized from EER analysis)

**Advantages**:
- Remote authentication capable
- Speaker-specific characteristics
- Robust to variations

---

## ğŸ“ Project Structure

```
multimodal_biometric_auth/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                                    # Main application entry point (1935 lines)
â”‚                                                 # - Streamlit web interface
â”‚                                                 # - 5 pages: Dashboard, Enrollment, Verification, 
â”‚                                                 #            Identification, Settings
â”‚                                                 # - Webcam/microphone integration
â”‚
â”œâ”€â”€ ğŸ“„ main.py                                   # CLI interface (alternative to web UI)
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                          # Python dependencies
â”‚                                                 # - opencv-python, numpy, scikit-image
â”‚                                                 # - tensorflow, deepface
â”‚                                                 # - torch, speechbrain
â”‚                                                 # - streamlit, plotly, librosa
â”‚
â”œâ”€â”€ ğŸ“„ README.md                                 # This documentation file
â”‚
â”œâ”€â”€ ğŸ“‚ config/                                   # Configuration management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                              # Global settings and constants
â”‚
â”œâ”€â”€ ğŸ“‚ modules/                                  # Core biometric recognition modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ‘† fingerprint_recognition.py            # Fingerprint module (650 lines)
â”‚   â”‚                                             # Algorithm: SIFT + FLANN matching
â”‚   â”‚                                             # Functions: enroll(), verify(), identify()
â”‚   â”‚                                             # Template: {keypoints, descriptors, metadata}
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ‘ï¸ iris_recognition.py                   # Iris module (929 lines)
â”‚   â”‚                                             # Algorithm: Daugman's + Gabor wavelets
â”‚   â”‚                                             # Features: Multi-eye support, auto-detection
â”‚   â”‚                                             # Template: {eyes: {left/right: {features, quality}}}
â”‚   â”‚                                             # Quality metrics: sharpness, contrast, illumination
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ˜Š face_recognition.py                   # Face module (580 lines)
â”‚   â”‚                                             # Algorithm: VGG-Face via DeepFace
â”‚   â”‚                                             # Detector: RetinaFace
â”‚   â”‚                                             # Template: {embeddings: [4096-D vectors]}
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ¤ voice_recognition.py                  # Voice module (720 lines)
â”‚                                                 # Algorithm: ECAPA-TDNN speaker embedding
â”‚                                                 # Preprocessing: VAD, resampling, normalization
â”‚                                                 # Template: {embedding: 192-D vector, metadata}
â”‚
â”œâ”€â”€ ğŸ“‚ data/                                     # Data storage directory
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ database/                             # Enrolled biometric templates
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ fingerprints/                     # Fingerprint templates (*.pkl)
â”‚   â”‚   â”‚   â””â”€â”€ {user_id}.pkl                    # SIFT features per user
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ iris/                             # Iris templates (*.pkl)
â”‚   â”‚   â”‚   â””â”€â”€ {user_id}.pkl                    # Multi-eye iris codes
â”‚   â”‚   â”‚                                         # Structure: {eyes: {left: {...}, right: {...}}}
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ faces/                            # Face templates (folders + images)
â”‚   â”‚   â”‚   â””â”€â”€ {user_id}/                       # One folder per user
â”‚   â”‚   â”‚       â”œâ”€â”€ face_1.jpg                   # Multiple face images
â”‚   â”‚   â”‚       â”œâ”€â”€ face_2.jpg
â”‚   â”‚   â”‚       â””â”€â”€ embeddings.pkl               # Pre-computed VGG-Face embeddings
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“‚ voices/                           # Voice templates (*.pkl)
â”‚   â”‚       â””â”€â”€ {user_id}.pkl                    # ECAPA-TDNN embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                                  # Sample test data
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ fingerprints/                     # Test fingerprint images
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ iris/                             # Test iris images (MMU dataset)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ faces/                            # Test face images
â”‚   â”‚   â””â”€â”€ ğŸ“‚ voices/                           # Test audio files
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ processed/                            # Preprocessed data cache
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                                # Jupyter notebooks for development
â”‚   â”œâ”€â”€ 01_fingerprint_development.ipynb         # Fingerprint algorithm testing
â”‚   â””â”€â”€ ğŸ“‚ data/                                 # Notebook-specific data
â”‚       â””â”€â”€ ğŸ“‚ fingerprints/
â”‚
â”œâ”€â”€ ğŸ“‚ results/                                  # Output files and reports
    â”œâ”€â”€ ğŸ“‚ logs/                                 # Application logs
    â”œâ”€â”€ ğŸ“‚ plots/                                # Performance visualizations
    â””â”€â”€ ğŸ“‚ reports/                              # Analysis reports

```

### Key Files Explained

| File | Lines | Purpose | Key Components |
|------|-------|---------|----------------|
| **app.py** | 1935 | Streamlit web UI | 5 pages, webcam/mic integration, real-time processing |
| **fingerprint_recognition.py** | 650 | Fingerprint processing | SIFT extraction, FLANN matching, Lowe's ratio test |
| **iris_recognition.py** | 929 | Iris processing | Hough Transform, Gabor wavelets, multi-eye support |
| **face_recognition.py** | 580 | Face processing | DeepFace wrapper, RetinaFace detector, cosine similarity |
| **voice_recognition.py** | 720 | Voice processing | VAD, ECAPA-TDNN, quality validation |

### Database Schema

#### Fingerprint Template (`{user_id}.pkl`)
```python
{
    'keypoints': List[cv2.KeyPoint],  # SIFT keypoints
    'descriptors': np.ndarray,         # Shape: (N, 128)
    'enrolled_date': datetime,
    'image_shape': (height, width)
}
```

#### Iris Template (`{user_id}.pkl`)
```python
{
    'eyes': {
        'left': {
            'iris_code': np.ndarray,        # Binary code (64Ã—512)
            'noise_mask': np.ndarray,       # Occlusion mask
            'iris_center': (x, y),
            'iris_radius': float,
            'pupil_center': (x, y),
            'pupil_radius': float,
            'quality_score': float,         # 0-1 range
            'enrolled_date': datetime
        },
        'right': {...}                      # Same structure
    },
    'enrolled_date': datetime
}
```

#### Face Template (`{user_id}/embeddings.pkl`)
```python
{
    'embeddings': [
        np.ndarray,  # Shape: (4096,) - VGG-Face embedding
        np.ndarray,  # Multiple embeddings per user
        ...
    ],
    'image_paths': List[str],
    'enrolled_date': datetime
}
```

#### Voice Template (`{user_id}.pkl`)
```python
{
    'embedding': np.ndarray,           # Shape: (192,) - ECAPA-TDNN
    'sample_rate': 16000,
    'duration': float,                 # seconds
    'quality_metrics': {
        'rms_energy': float,
        'zero_crossing_rate': float,
        'spectral_centroid': float
    },
    'enrolled_date': datetime
}
```

### Module Dependencies

```
app.py
  â”œâ”€â”€ modules.fingerprint_recognition
  â”œâ”€â”€ modules.iris_recognition
  â”œâ”€â”€ modules.face_recognition
  â””â”€â”€ modules.voice_recognition

fingerprint_recognition.py
  â”œâ”€â”€ cv2 (OpenCV)
  â”œâ”€â”€ numpy
  â””â”€â”€ pickle

iris_recognition.py
  â”œâ”€â”€ cv2 (OpenCV)
  â”œâ”€â”€ numpy
  â”œâ”€â”€ scipy
  â””â”€â”€ pickle

face_recognition.py
  â”œâ”€â”€ deepface
  â”œâ”€â”€ tensorflow
  â””â”€â”€ pickle

voice_recognition.py
  â”œâ”€â”€ speechbrain
  â”œâ”€â”€ torch
  â”œâ”€â”€ librosa
  â””â”€â”€ soundfile
```

---

## ğŸ“Š Performance

### Accuracy Metrics (Tested)

| Modality    | GAR (%)* | FAR (%)** | Threshold | Notes                    |
|-------------|----------|-----------|-----------|--------------------------|
| Fingerprint | ~95      | <5        | Auto      | SIFT with FLANN          |
| Iris        | 66.7     | 0.0       | 0.65      | Multi-eye, validated     |
| Face        | ~98      | <1        | Auto      | DeepFace VGG-Face        |
| Voice       | ~100     | 0.0       | 0.50      | EER 0.00% in development |

*GAR: Genuine Accept Rate  
**FAR: False Accept Rate

### Processing Speed

| Operation           | Fingerprint | Iris   | Face   | Voice  |
|---------------------|-------------|--------|--------|--------|
| Enrollment          | ~2s         | ~3s    | ~1s    | ~2s    |
| Verification (1:1)  | ~1s         | ~2s    | <1s    | <1s    |
| Identification (1:N)| ~0.5s/user  | ~1s/user| <0.1s/user| <0.1s/user|

*Tested on: Intel Core i7-11370H, 16GB RAM LPDDR4X, no GPU acceleration

---

## ğŸ”’ Security

### Template Protection

Each biometric modality stores **privacy-preserving representations** instead of raw biometric data:

| Modality | Template Type | Reversibility | Size |
|----------|---------------|---------------|------|
| **Fingerprint** | SIFT keypoints + descriptors | âŒ Non-reversible | ~50-200 KB |
| **Iris** | Binary iris codes (Gabor-filtered) | âŒ Non-reversible | ~4 KB |
| **Face** | VGG-Face embeddings (4096-D) | âŒ Non-reversible | ~16 KB |
| **Voice** | ECAPA-TDNN embeddings (192-D) | âŒ Non-reversible | ~1.5 KB |

**Why templates are secure:**
- Cannot reconstruct original biometric image/audio from templates
- Mathematical transformations are one-way functions
- Even if database is stolen, attackers cannot reverse-engineer biometrics

### Security Measures Implemented

âœ… **Local Storage**: All templates stored locally (`data/database/`), no cloud transmission

âœ… **Threshold Validation**: Configurable similarity thresholds prevent unauthorized access

âœ… **Quality Assessment**: Poor quality samples rejected during enrollment
  - Iris: Sharpness, contrast, illumination, occlusion checks
  - Voice: Duration, energy, RMS validation
  - Face: Detection confidence scoring

âœ… **Critical Bugs Fixed** (November 2025):
  - **Iris Gabor Filter Bug**: Fixed threshold causing 100% FAR â†’ Now 0% FAR
  - **UI Threshold Mismatch**: Fixed parameter confusion (Hamming vs Similarity)

âœ… **Multi-Template Storage**: 
  - Face: Multiple images per user for robustness
  - Iris: Separate left/right eye templates

âœ… **Auto-Migration**: Old template formats automatically upgraded

### Known Limitations

âš ï¸ **Anti-Spoofing**: Not implemented
  - Vulnerable to printed fingerprints, photos, recordings
  - **Recommendation**: Add liveness detection

âš ï¸ **Database Encryption**: Templates stored in plain pickle files
  - **Recommendation**: Use encrypted database (SQLite with encryption)

âš ï¸ **No User Authentication**: Anyone can access the web interface
  - **Recommendation**: Add login system with role-based access

âš ï¸ **No Rate Limiting**: Unlimited verification attempts
  - **Recommendation**: Implement attempt throttling (max 3 tries/minute)

âš ï¸ **Pickle Security**: Using pickle for serialization has security risks
  - **Recommendation**: Switch to JSON/Protocol Buffers for production

### Recommendations for Production Deployment

1. **Add Liveness Detection**
   - Fingerprint: Pulse detection, perspiration analysis
   - Iris: Pupil response to light
   - Face: 3D depth analysis, blink detection
   - Voice: Challenge-response prompts

2. **Implement Encryption**
   - Encrypt templates at rest (AES-256)
   - Use HTTPS for web interface
   - Secure key management (HSM/KMS)

3. **Add Authentication Layer**
   - User login before biometric operations
   - Role-based access control (admin, user)
   - Audit logging for all operations

4. **Database Improvements**
   - Migrate from Pickle to PostgreSQL/MongoDB
   - Use ORMs (SQLAlchemy) for safe queries
   - Regular backups with encryption

5. **Compliance**
   - GDPR compliance (data retention, user consent)
   - ISO/IEC 30107 (anti-spoofing)
   - FIDO2/WebAuthn integration for web security

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guide for Python code
- Add docstrings to all functions (Google style)
- Include unit tests for new features
- Update README.md if adding new functionality
- Test with multiple biometric samples before submitting

### Areas for Improvement

#### High Priority
- [ ] **Liveness Detection**: Add anti-spoofing for face/iris
- [ ] **Unit Tests**: Comprehensive pytest suite for all modules
- [ ] **Database Encryption**: Secure template storage
- [ ] **User Authentication**: Login system with JWT

#### Medium Priority
- [ ] **API Development**: RESTful API for remote access
- [ ] **Multi-factor Authentication**: Combine multiple biometrics
- [ ] **Performance Optimization**: GPU acceleration for deep learning
- [ ] **Docker Support**: Containerized deployment

#### Low Priority
- [ ] **Mobile App**: React Native/Flutter integration
- [ ] **Jupyter Notebooks**: Add for Iris/Face/Voice (only Fingerprint exists)
- [ ] **Voice Quality**: Alternative to `st.audio_input()` for better recording
- [ ] **Export Reports**: PDF generation for identification results

### Bug Reports

Found a bug? Please include:
- Steps to reproduce
- Expected vs actual behavior
- Screenshots/error messages
- System information (OS, Python version)

## ğŸ™ Acknowledgments

- **SIFT Algorithm**: David Lowe
- **Daugman's Iris Recognition**: John Daugman
- **DeepFace**: Serengil, S. I., & Ozpinar, A. (2020)
- **SpeechBrain**: Ravanelli et al. (2021)
- **MMU Iris Database**: Multimedia University
- **Streamlit**: For the amazing web framework

---

## ğŸ“ Contact

Project Maintainer: Lewis Chu
- Email: tgefps2004@gmail.com
- GitHub: [@lewisMVP](https://github.com/lewisMVP)


**â­ If you find this project useful, please give it a star!**

**ğŸ› Found a bug? [Open an issue](https://github.com/lewisMVP/multimodal-biometric-authentication/issues)**

**ğŸ’¡ Have a feature request? [Start a discussion](https://github.com/lewisMVP/multimodal-biometric-authentication/discussions)**
